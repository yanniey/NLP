{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 3 version of the Pluralsight course: Getting Started with Natural Language Processing with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Autosummarise a Washington Post news article using rule-based methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextWaPo(url):\n",
    "    r = requests.get(url)\n",
    "    r.encoding = 'utf-8'\n",
    "    html = r.text\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    text = \" \".join(map(lambda p:p.text, soup.find_all('article')))\n",
    "    return text\n",
    "\n",
    "url = \"https://www.washingtonpost.com/technology/2019/05/02/facebook-bans-extremist-leaders-including-louis-farrakhan-alex-jones-milo-yiannopoulos-being-dangerous/?utm_term=.c8fe12bd52c7\"\n",
    "text = getTextWaPo(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**soup.find()** only returns the first element that matches the **article** tag\n",
    "    \n",
    "**soup.findall()** returns all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = sent_tokenize(text)\n",
    "word_sent = word_tokenize(text.lower())\n",
    "\n",
    "# remove stopwords\n",
    "_stopwords = set(stopwords.words(\"english\") + list(punctuation)+['’','“','”','—',\"window.powaBoot\"])\n",
    "word_sent = [word for word in word_sent if word not in _stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the most frequent words in the article\n",
    "from nltk.probability import FreqDist\n",
    "freq = FreqDist(word_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['facebook',\n",
       " 'said',\n",
       " 'hate',\n",
       " 'banned',\n",
       " 'jones',\n",
       " 'white',\n",
       " 'company',\n",
       " 'infowars',\n",
       " 'speech',\n",
       " 'platforms']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from heapq import nlargest\n",
    "# use nlargest to find the top 10 most frequent keywords in the article\n",
    "nlargest(10,freq,key=freq.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Facebook said on Thursday it has permanently banned several far-right and anti-Semitic figures and organizations, including Nation of Islam leader Louis Farrakhan, Infowars host Alex Jones, Milo Yiannopoulos and Laura Loomer, for being “dangerous,” a sign that the social network is more aggressively enforcing its hate speech policies under pressure from civil rights groups.',\n",
       " 'Angelo Carusone, president of Media Matters, an organization that has long advocated for more enforcement against white supremacists, said Facebook has been lax against enforcing its policies against hate speech on these accounts because the company doesn’t want to deal with the right-wing blowback.',\n",
       " 'Madihha Ahussain, special counsel for anti-Muslim bigotry with the advocacy group Muslim Advocates, said that individuals like Loomer, Jones and Yiannopoulos have used social media platforms to broadcast dangerous hate speech and conspiracies targeting Muslims, Jews and others.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from heapq import nlargest\n",
    "ranking  = defaultdict(int)\n",
    "\n",
    "# find the most sentences with the most frequent words, and store result into a defaultdict where the keys are the indices of the sentences, and the values are the significance scores for the sentences (which is the sum of the importance of words in that sentence)\n",
    "for i, sent in enumerate(sents):\n",
    "    for w in word_tokenize(sent.lower()):\n",
    "        if w in freq:\n",
    "            ranking[i] +=freq[w]\n",
    "            \n",
    "# find the top 3 sentences from the ranking dictionary\n",
    "\n",
    "sent_index = nlargest(3, ranking,key=ranking.get)\n",
    "sent_index\n",
    "[sents[j] for j in sorted(sent_index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting everything together in one function:\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "from heapq import nlargest\n",
    "\n",
    "def summarize(text,n):\n",
    "    sents = sent_tokenize(text)\n",
    "    \n",
    "    assert n <= len(sents) # this checks whether the number of summary lines is smaller than the # of sentences in the article\n",
    "    word_sent = word_tokenize(text.lower())\n",
    "    _stopwords = set(stopwords.words(\"english\") + list(punctuation)+['’','“','”','—'])\n",
    "    \n",
    "    word_sent = [word for word in word_sent if word not in _stopwords]\n",
    "    freq = FreqDist(word_sent)\n",
    "    \n",
    "    ranking = defaultdict(int)\n",
    "    \n",
    "    for i, sent in enumerate(sents):\n",
    "        for w in word_tokenize(sent.lower()):\n",
    "            if w in freq:\n",
    "                ranking[i]+= freq[w]\n",
    "    \n",
    "    sent_index = nlargest(4, ranking,key=ranking.get)\n",
    "    return [sents[j] for j in sorted(sent_index)]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Facebook said on Thursday it has permanently banned several far-right and anti-Semitic figures and organizations, including Nation of Islam leader Louis Farrakhan, Infowars host Alex Jones, Milo Yiannopoulos and Laura Loomer, for being “dangerous,” a sign that the social network is more aggressively enforcing its hate speech policies under pressure from civil rights groups.',\n",
       " 'Facebook had removed the accounts, fan pages, and groups affiliated with these individuals after it reevaluated the content that they had posted previously, or had reexamined their activities outside of Facebook, the company said.',\n",
       " 'Angelo Carusone, president of Media Matters, an organization that has long advocated for more enforcement against white supremacists, said Facebook has been lax against enforcing its policies against hate speech on these accounts because the company doesn’t want to deal with the right-wing blowback.',\n",
       " 'Madihha Ahussain, special counsel for anti-Muslim bigotry with the advocacy group Muslim Advocates, said that individuals like Loomer, Jones and Yiannopoulos have used social media platforms to broadcast dangerous hate speech and conspiracies targeting Muslims, Jews and others.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(text,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
